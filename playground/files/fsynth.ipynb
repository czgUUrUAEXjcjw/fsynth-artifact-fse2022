{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# FSynth Playground",
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": "We start with a few prerequisites.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import enum\nimport heapq\nimport sys\nimport string\nimport random",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## FSynth",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Status codes",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class Status(enum.Enum):\n    Complete = 0\n    Incomplete = 1\n    Incorrect = -1",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Insertion Alphabet",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "CHARACTERS = string.printable",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Insertion Index",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This is used to indicate whether insertion should be tried anywhere in the prefix or only in the last index.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "LAST_INSERT_ONLY = True",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### MAX_SIMULTANIOUS_CORRECTIONS\n\nWe will have a number of simultaneous plausible fixes at each step. Unfortunately, as the number of such plausible fixes increase, the performance decreases. Hence, with this, we can restrict such simultaneous threads to the best N. The priorities are determined based on (1) the smallest number of repairs (2) maximum boundary (advancement) possible.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "MAX_SIMULTANIOUS_CORRECTIONS = 5 # set it to a positive number to restrict the queue.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def filter_best(items):\n    if MAX_SIMULTANIOUS_CORRECTIONS < 0: return items\n    boundaries = sorted({i.boundary for i in items}, reverse=True)\n    return [i for i in items if i.boundary in  boundaries[:MAX_SIMULTANIOUS_CORRECTIONS]]",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### MAX_NUM_PER_MASK",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This setting controls the number of samples that we evaluate per a given mask.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# the incomplete substring is one behind boundary. i.e inputval[:boundary] \nMAX_NUM_PER_MASK = 1",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# at the boundary, it is always wrong.\n\n# We need to sample from inserts and modifiers to prevent them growing\n# out of bounds. The idea is to collect all delete,insert,modification indexes\n# and form a mask. i.e 3D_4I_5M means that at boundary 3, deletion happened,\n# then, in the resulting string, at boundary4, insertion happenbed, and in the\n# resuting, at boundary 5, modification happened. Then, we sample from the\n# items with same mask. This needs to be done before extending. That is, each\n# extend, we should test all possible character extensions on the sampled\n# strings.\n\ndef sample_items_by_mask(items):\n    # sample here. We only want a fixed number of items per mask.\n    masks = {}\n    for i in items:\n        key = (i.mask, i.boundary, i.inputstr[i.boundary-1:i.boundary])\n        if i.mask not in masks: masks[key] = []\n        masks[key].append(i)\n\n    sampled = []\n    for key in masks:\n        if len(masks[key]) < MAX_NUM_PER_MASK:\n            res = masks[key]\n        else:\n            res = random.sample(masks[key], MAX_NUM_PER_MASK)\n        sampled.extend(res)\n    return filter_best(sampled)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### FSynth Repair",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class Repair:\n    def __repr__(self):\n        s = repr(str(self))\n        v = (self.inputstr, self.boundary, s)\n        return repr(v)\n\n    def set_boundary(self, b):\n        assert b >= 0\n        self.boundary = b\n\n    def __str__(self):\n        return self.inputstr[:self.boundary]\n\n    def __init__(self, inputstr, boundary, mask='', extended=False):\n        assert boundary >= 0\n        self.inputstr, self.boundary = inputstr, boundary\n        self.extended = extended\n        self.mask = mask\n        self._status = None\n\n    def test(self, mystr):\n        return validate(mystr)\n\n    def status(self):\n        if self._status is not None: return self._status\n        self._status = self.my_status()\n        return self._status\n\n    def my_status(self):\n        my_str = self.inputstr[:self.boundary]\n        if self.test(my_str)[0] == Status.Incorrect: return Status.Incorrect\n        if self.test(my_str)[0] == Status.Incomplete: return Status.Incomplete\n        # verify this is actually complete. For example, given [*1], [] is not\n        # complete. It is likely incorrect. The other chance is 12*45 where\n        # 123 is (it is not complete!) incomplete rather than incorrect. To\n        # check this, we need to check the next index too.\n        if self.boundary >= len(self.inputstr): return Status.Complete\n        my_str = self.inputstr[:self.boundary + 1]\n        if self.test(my_str)[0] == Status.Incorrect: return Status.Incorrect\n        if self.test(my_str)[0] == Status.Incomplete: return Status.Incomplete\n\n        # because if 123*5 is fixed to 12395 is complete, then 1239 is\n        # incomplete\n        return Status.Incomplete\n\n    def is_incomplete(self):\n        return self.status() == Status.Incomplete\n\n    def is_incorrect(self):\n        return self.status() == Status.Incorrect\n\n    def is_complete(self):\n        return self.status() == Status.Complete\n\n    def apply_delete(self):\n        return Repair(self.inputstr[:self.boundary] +\n                      self.inputstr[self.boundary + 1:], self.boundary,\n                      mask='%s_D%d' % (self.mask, self.boundary)).extend_deleted_item()\n\n    def insert_at(self, k, i, suffix):\n        v = self.inputstr[:k] + i + self.inputstr[k:self.boundary] + suffix\n        new_item = Repair(v, k, mask='%s_I%d' % (self.mask, k))\n        ie = new_item.extend_inserted_item()\n        if ie.boundary > k:\n            return ie\n        return None\n\n    # one of the problems with deletion is that we do not know exactly where the\n    # character was deleted from, eventhough the parser can be conforming. For\n    # example, given an original string \"[1,2,3]\", where the corruption happened\n    # at the first character, we will only get the failure at the last\n    # character. Hence to be accurate, what we shouuld do is to try insert all\n    # characters everywhere, and see if it helps. This is ofcourse not a very\n    # easy task. So we control this behavior with a switch.\n    def insert_char(self, i):\n        suffix = self.inputstr[self.boundary:]\n        return_lst = []\n        if LAST_INSERT_ONLY:\n            v = self.insert_at(self.boundary, i, suffix)\n            if v is not None: return_lst.append(v)\n        else:\n            # the repair could be any where from 0 to self.boundary (inclusive).\n            # So we try all\n            for k in range(self.boundary):\n                v = self.insert_at(k,i, suffix)\n                if v is not None: return_lst.append(v)\n        return return_lst\n\n    def apply_insert(self):\n        new_items = []\n        for i in CHARACTERS:\n            items = self.insert_char(i)\n            if items:\n                new_items.extend(items)\n        return new_items\n\n    def bsearch_extend_item(self):\n        bs = binary_search(self.inputstr, left=self.boundary, check=check_is_incomplete)\n        assert bs >= 0\n        if bs >= len(self.inputstr):\n            self.set_boundary(bs)\n            self.extended = True\n            return self\n        # e = self.inputstr[bs] # error causing char.\n        self.set_boundary(bs)\n        return self\n\n    # there are many more invalid inserts than valid inserts. So searching the\n    # whole file again is not useful.\n    def lsearch_extend_item(self, nxt=1):\n        # need to be done on the item becauese of invariant.\n        while True:\n            # assert boundary+nxt <= len(inputstr) <- inserts can overshoot\n            if (self.boundary + nxt) > len(self.inputstr):\n                assert len(self.inputstr) == (self.boundary + nxt - 1)\n                self.set_boundary (self.boundary + nxt - 1)\n                self.extended = True\n                return self\n            s = Repair(self.inputstr, self.boundary + nxt)\n            if s.is_incomplete():\n                #return self.extend_deleted_item()\n                nxt += 1\n                continue\n            if s.is_incorrect():\n                # the current nxt is bad, so go back to previous\n                self.set_boundary(self.boundary + nxt - 1)\n                self.extended = True\n                return self\n            if s.is_complete():\n                self.set_boundary(self.boundary + nxt)\n                self.extended = True\n                return self\n            assert False\n        assert False\n\n    def extend_deleted_item(self):\n        assert self._status is None\n        assert not self.extended\n        return self.bsearch_extend_item()\n        #return self.lsearch_extend_item(nxt=0)\n\n    def extend_inserted_item(self):\n        assert self._status is None\n        assert not self.extended\n        return self.lsearch_extend_item(nxt=1)\n        #return self.bsearch_extend_item()\n\n    def repair_and_extend(self):\n        e_arr = []\n        item_d = self.apply_delete()\n        e_arr.append(item_d)\n\n        # for insert only append if it resulted in a boundary increase\n        new_items = self.apply_insert()\n        e_arr.extend(new_items)\n        return e_arr",
      "metadata": {
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Binary Search",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def binary_search(array, left = 0, right = None, check=None):\n    if not array: return left\n    left, right = 0, len(array) - 1\n\n    #if not check(array, left):\n    #    return left\n    assert check(array, left)\n\n    if check(array, right):\n        return len(array)-1\n    # Main loop which narrows our search range.\n    while left + 1 < right:\n        middle = (left + right) // 2\n        if check(array, middle):\n            left = middle\n        else:\n            right = middle\n    return left",
      "metadata": {
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "FLAG=None",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def find_fixes(inputval, boundary):\n    global FLAG\n    # First start with zero edit distance\n    # priority, item where item is an array of elements\n    next_items = [Repair(inputval, boundary, extended=True)]\n    edit_dist = 0\n    while True:\n        FLAG = edit_dist\n        # fetch the first rank groups.\n        current_items = next_items\n        next_items = []\n        chosen_items = sample_items_by_mask(current_items)\n        completed = []\n        for item in chosen_items:\n            # try repair and extending each item until we get incorrect.\n            new_items = item.repair_and_extend()\n\n            for i in new_items:\n                next_items.append(i)\n                if i.is_complete():\n                    completed.append(i)\n                    yield i\n        if completed:\n            break\n        edit_dist += 1\n    assert False",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def check_is_incomplete(sval, i):\n    s_ = Repair(sval, i)\n    s = str(s_)\n    return s_.is_incomplete()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def repair(inputval):\n    assert check_is_incomplete(inputval, 0) # 1\n    # assert not check_is_incomplete(inputval, len(inputval))\n    # first do binary search to find the boundary\n    # not a requirement. Extend item will do as well.\n    boundary = binary_search(inputval, check=check_is_incomplete)\n    c = inputval[boundary] # this should be the error causing char.\n    assert check_is_incomplete(inputval, boundary)\n    # assert not check_is_incomplete(inputval, boundary+1)\n    return find_fixes(inputval, boundary)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "TESTED = {}\n\ndef validate(input_str):\n    if input_str in TESTED: return TESTED[input_str]\n    TESTED[input_str] = validate_json(input_str)\n    return TESTED[input_str]",
      "metadata": {
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Conforming JSON Parser",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import json\n\nTESTED = {}\nnum_runs: int = 0\n\ndef logit(*v):\n    print(FLAG, *v)\n    return\n\n# check if jstr fits in this context.\ndef it_fits(input_str):\n    try:\n        json.loads(input_str)\n        logit('*', repr(input_str))\n        return True\n    except Exception as e:\n        msg = str(e)\n        if msg.startswith('Expecting'):\n            # Expecting value: line 1 column 4 (char 3)\n            n = int(msg.rstrip(')').split()[-1])\n            if n >= len(input_str):\n                logit('+', repr(input_str))\n                return True\n        return False\n\n\ndef validate_json(input_str):\n    global num_runs\n    num_runs += 1\n    try:\n        json.loads(input_str)\n        logit('*', repr(input_str))\n        return Status.Complete, -1, ''\n    except Exception as e:\n        msg = str(e)\n        if msg.startswith('Expecting'):\n            # Expecting value: line 1 column 4 (char 3)\n            n = int(msg.rstrip(')').split()[-1])\n            # If the error is 'outside' the string, it can still be valid\n            if n >= len(input_str):\n                logit('+', repr(input_str))\n                return Status.Incomplete, n, ''\n            elif len(input_str) > 1 and input_str[-1] == '.' and input_str[-2].isdigit():\n                # JSON returns incorrect for [3. rather than incomplete.\n                return Status.Incomplete, n, ''\n            else:\n                logit('X', repr(input_str))\n                remaining = input_str[n:]\n                if remaining in ['t', 'tr', 'tru']:\n                    # check if it fits first.\n                    if it_fits(input_str[:n] + 'true'):\n                        return Status.Incomplete, n, input_str[n]\n                    return Status.Incorrect, n, input_str[n]\n                if remaining in ['f', 'fa', 'fal', 'fals']:\n                    if it_fits(input_str[:n] + 'false'):\n                        return Status.Incomplete, n, input_str[n]\n                    return Status.Incorrect, n, input_str[n]\n                if remaining in ['n', 'nu', 'nul']:\n                    if it_fits(input_str[:n] + 'null'):\n                        return Status.Incomplete, n, input_str[n]\n                    return Status.Incorrect, n, input_str[n]\n                return Status.Incorrect, n, input_str[n]\n        elif msg.startswith('Unterminated'):\n            # Unterminated string starting at: line 1 column 1 (char 0)\n            n = int(msg.rstrip(')').split()[-1])\n            if n >= len(input_str):\n                logit('+', repr(input_str))\n                return Status.Incomplete, n, ''\n            else:\n                logit('+', repr(input_str))\n                return Status.Incomplete, n, input_str[n]\n        elif msg.startswith('Extra data'):\n            n = int(msg.rstrip(')').split()[-1])\n            if n >= len(input_str):\n                logit('X', repr(input_str))\n                return Status.Incorrect, n, ''\n            else:\n                logit('X', repr(input_str))\n                return Status.Incorrect, n, input_str[n]\n        elif msg.startswith('Invalid '):\n            idx = msg.find('(char ')\n            eidx = msg.find(')')\n            s = msg[idx + 6:eidx]\n            n = int(s)\n            logit('X', repr(input_str))\n            return Status.Incorrect, n, input_str[n]\n        else:\n            raise e",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Evaluation",
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": "FSynth relies on the ability to quickly verify a very large number of results. Unfortunately, this makes usual set of characters unsuitable for Python over WASM as it introduces a few orders of magnitude performance penalty. Hence, we limit our characters.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "CHARACTERS = ['[', ']', '{', '}', '\"', ',', '.'] + [i for i in string.digits]",
      "metadata": {
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def fsynth(inputval):\n    fixes = []\n    for fix in repair(inputval):\n        fixes.append(fix)\n        break  # Return only the first fix\n    for fix in fixes:\n        print('FIXED', repr(str(fix)))\n    print(f\"Number of oracle runs required for fixing this input: {num_runs}\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "inputstr = '[*,+]'\nfsynth(inputstr)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "text": "None + ''\nNone X '[*,+'\nNone X '[*'\nNone + '['\n0 X '[,+'\n0 X '[,'\n0 + '[['\n0 X '[[*'\n0 * '[]'\n0 X '[]*'\n0 + '[{'\n0 X '[{*'\n0 X '[}'\n0 + '[\"'\n0 + '[\"*'\n0 + '[\"*,'\n0 + '[\"*,+'\n0 + '[\"*,+]'\n0 X '[.'\n0 + '[0'\n0 X '[0*'\n0 + '[1'\n0 X '[1*'\n0 + '[2'\n0 X '[2*'\n0 + '[3'\n0 X '[3*'\n0 + '[4'\n0 X '[4*'\n0 + '[5'\n0 X '[5*'\n0 + '[6'\n0 X '[6*'\n0 + '[7'\n0 X '[7*'\n0 + '[8'\n0 X '[8*'\n0 + '[9'\n0 X '[9*'\n1 X '[+'\n1 X '[[,'\n1 X '[],'\n1 X '[{,'\n1 + '[\",'\n1 + '[\",+'\n1 + '[\",+]'\n1 + '[0,'\n1 X '[0,+'\n1 + '[1,'\n1 X '[1,+'\n1 + '[2,'\n1 X '[2,+'\n1 + '[3,'\n1 X '[3,+'\n1 + '[4,'\n1 X '[4,+'\n1 + '[5,'\n1 X '[5,+'\n1 + '[6,'\n1 X '[6,+'\n1 + '[7,'\n1 X '[7,+'\n1 + '[8,'\n1 X '[8,+'\n1 + '[9,'\n1 X '[9,+'\n1 X '[[,+'\n1 + '[[['\n1 X '[[[*'\n1 + '[[]'\n1 X '[[]*'\n1 + '[[{'\n1 X '[[{*'\n1 X '[[}'\n1 + '[[\"'\n1 + '[[\"*'\n1 + '[[\"*,'\n1 + '[[\"*,+'\n1 + '[[\"*,+]'\n1 X '[[.'\n1 + '[[0'\n1 X '[[0*'\n1 + '[[1'\n1 X '[[1*'\n1 + '[[2'\n1 X '[[2*'\n1 + '[[3'\n1 X '[[3*'\n1 + '[[4'\n1 X '[[4*'\n1 + '[[5'\n1 X '[[5*'\n1 + '[[6'\n1 X '[[6*'\n1 + '[[7'\n1 X '[[7*'\n1 + '[[8'\n1 X '[[8*'\n1 + '[[9'\n1 X '[[9*'\n1 X '[{,+'\n1 X '[{['\n1 X '[{]'\n1 X '[{{'\n1 + '[{}'\n1 X '[{}*'\n1 + '[{\"'\n1 + '[{\"*'\n1 + '[{\"*,'\n1 + '[{\"*,+'\n1 + '[{\"*,+]'\n1 X '[{.'\n1 X '[{0'\n1 X '[{1'\n1 X '[{2'\n1 X '[{3'\n1 X '[{4'\n1 X '[{5'\n1 X '[{6'\n1 X '[{7'\n1 X '[{8'\n1 X '[{9'\n1 + '[\"*,+]['\n1 + '[\"*,+]]'\n1 + '[\"*,+]{'\n1 + '[\"*,+]}'\n1 + '[\"*,+]\"'\n1 + '[\"*,+],'\n1 + '[\"*,+].'\n1 + '[\"*,+]0'\n1 + '[\"*,+]1'\n1 + '[\"*,+]2'\n1 + '[\"*,+]3'\n1 + '[\"*,+]4'\n1 + '[\"*,+]5'\n1 + '[\"*,+]6'\n1 + '[\"*,+]7'\n1 + '[\"*,+]8'\n1 + '[\"*,+]9'\n1 X '[0['\n1 * '[0]'\n1 X '[0]*'\n1 X '[0{'\n1 X '[0}'\n1 X '[0\"'\n1 X '[0,*'\n1 X '[0.*'\n1 X '[00'\n1 X '[01'\n1 X '[02'\n1 X '[03'\n1 X '[04'\n1 X '[05'\n1 X '[06'\n1 X '[07'\n1 X '[08'\n1 X '[09'\n1 X '[1['\n1 * '[1]'\n1 X '[1]*'\n1 X '[1{'\n1 X '[1}'\n1 X '[1\"'\n1 X '[1,*'\n1 X '[1.*'\n1 + '[10'\n1 X '[10*'\n1 + '[11'\n1 X '[11*'\n1 + '[12'\n1 X '[12*'\n1 + '[13'\n1 X '[13*'\n1 + '[14'\n1 X '[14*'\n1 + '[15'\n1 X '[15*'\n1 + '[16'\n1 X '[16*'\n1 + '[17'\n1 X '[17*'\n1 + '[18'\n1 X '[18*'\n1 + '[19'\n1 X '[19*'\n1 X '[2['\n1 * '[2]'\n1 X '[2]*'\n1 X '[2{'\n1 X '[2}'\n1 X '[2\"'\n1 X '[2,*'\n1 X '[2.*'\n1 + '[20'\n1 X '[20*'\n1 + '[21'\n1 X '[21*'\n1 + '[22'\n1 X '[22*'\n1 + '[23'\n1 X '[23*'\n1 + '[24'\n1 X '[24*'\n1 + '[25'\n1 X '[25*'\n1 + '[26'\n1 X '[26*'\n1 + '[27'\n1 X '[27*'\n1 + '[28'\n1 X '[28*'\n1 + '[29'\n1 X '[29*'\n1 X '[3['\n1 * '[3]'\n1 X '[3]*'\n1 X '[3{'\n1 X '[3}'\n1 X '[3\"'\n1 X '[3,*'\n1 X '[3.*'\n1 + '[30'\n1 X '[30*'\n1 + '[31'\n1 X '[31*'\n1 + '[32'\n1 X '[32*'\n1 + '[33'\n1 X '[33*'\n1 + '[34'\n1 X '[34*'\n1 + '[35'\n1 X '[35*'\n1 + '[36'\n1 X '[36*'\n1 + '[37'\n1 X '[37*'\n1 + '[38'\n1 X '[38*'\n1 + '[39'\n1 X '[39*'\n1 X '[4['\n1 * '[4]'\n1 X '[4]*'\n1 X '[4{'\n1 X '[4}'\n1 X '[4\"'\n1 X '[4,*'\n1 X '[4.*'\n1 + '[40'\n1 X '[40*'\n1 + '[41'\n1 X '[41*'\n1 + '[42'\n1 X '[42*'\n1 + '[43'\n1 X '[43*'\n1 + '[44'\n1 X '[44*'\n1 + '[45'\n1 X '[45*'\n1 + '[46'\n1 X '[46*'\n1 + '[47'\n1 X '[47*'\n1 + '[48'\n1 X '[48*'\n1 + '[49'\n1 X '[49*'\n1 X '[5['\n1 * '[5]'\n1 X '[5]*'\n1 X '[5{'\n1 X '[5}'\n1 X '[5\"'\n1 X '[5,*'\n1 X '[5.*'\n1 + '[50'\n1 X '[50*'\n1 + '[51'\n1 X '[51*'\n1 + '[52'\n1 X '[52*'\n1 + '[53'\n1 X '[53*'\n1 + '[54'\n1 X '[54*'\n1 + '[55'\n1 X '[55*'\n1 + '[56'\n1 X '[56*'\n1 + '[57'\n1 X '[57*'\n1 + '[58'\n1 X '[58*'\n1 + '[59'\n1 X '[59*'\n1 X '[6['\n1 * '[6]'\n1 X '[6]*'\n1 X '[6{'\n1 X '[6}'\n1 X '[6\"'\n1 X '[6,*'\n1 X '[6.*'\n1 + '[60'\n1 X '[60*'\n1 + '[61'\n1 X '[61*'\n1 + '[62'\n1 X '[62*'\n1 + '[63'\n1 X '[63*'\n1 + '[64'\n1 X '[64*'\n1 + '[65'\n1 X '[65*'\n1 + '[66'\n1 X '[66*'\n1 + '[67'\n1 X '[67*'\n1 + '[68'\n1 X '[68*'\n1 + '[69'\n1 X '[69*'\n1 X '[7['\n1 * '[7]'\n1 X '[7]*'\n1 X '[7{'\n1 X '[7}'\n1 X '[7\"'\n1 X '[7,*'\n1 X '[7.*'\n1 + '[70'\n1 X '[70*'\n1 + '[71'\n1 X '[71*'\n1 + '[72'\n1 X '[72*'\n1 + '[73'\n1 X '[73*'\n1 + '[74'\n1 X '[74*'\n1 + '[75'\n1 X '[75*'\n1 + '[76'\n1 X '[76*'\n1 + '[77'\n1 X '[77*'\n1 + '[78'\n1 X '[78*'\n1 + '[79'\n1 X '[79*'\n1 X '[8['\n1 * '[8]'\n1 X '[8]*'\n1 X '[8{'\n1 X '[8}'\n1 X '[8\"'\n1 X '[8,*'\n1 X '[8.*'\n1 + '[80'\n1 X '[80*'\n1 + '[81'\n1 X '[81*'\n1 + '[82'\n1 X '[82*'\n1 + '[83'\n1 X '[83*'\n1 + '[84'\n1 X '[84*'\n1 + '[85'\n1 X '[85*'\n1 + '[86'\n1 X '[86*'\n1 + '[87'\n1 X '[87*'\n1 + '[88'\n1 X '[88*'\n1 + '[89'\n1 X '[89*'\n1 X '[9['\n1 * '[9]'\n1 X '[9]*'\n1 X '[9{'\n1 X '[9}'\n1 X '[9\"'\n1 X '[9,*'\n1 X '[9.*'\n1 + '[90'\n1 X '[90*'\n1 + '[91'\n1 X '[91*'\n1 + '[92'\n1 X '[92*'\n1 + '[93'\n1 X '[93*'\n1 + '[94'\n1 X '[94*'\n1 + '[95'\n1 X '[95*'\n1 + '[96'\n1 X '[96*'\n1 + '[97'\n1 X '[97*'\n1 + '[98'\n1 X '[98*'\n1 + '[99'\n1 X '[99*'\n2 X '[[+'\n2 X '[]+'\n2 X '[{+'\n2 + '[\"+'\n2 + '[\"+]'\n2 X '[0+'\n2 X '[1+'\n2 X '[2+'\n2 X '[3+'\n2 X '[4+'\n2 X '[5+'\n2 X '[6+'\n2 X '[7+'\n2 X '[8+'\n2 X '[9+'\n2 X '[[[,'\n2 + '[[],'\n2 X '[[],+'\n2 X '[[{,'\n2 + '[[\",'\n2 + '[[\",+'\n2 + '[[\",+]'\n2 + '[[0,'\n2 X '[[0,+'\n2 + '[[1,'\n2 X '[[1,+'\n2 + '[[2,'\n2 X '[[2,+'\n2 + '[[3,'\n2 X '[[3,+'\n2 + '[[4,'\n2 X '[[4,+'\n2 + '[[5,'\n2 X '[[5,+'\n2 + '[[6,'\n2 X '[[6,+'\n2 + '[[7,'\n2 X '[[7,+'\n2 + '[[8,'\n2 X '[[8,+'\n2 + '[[9,'\n2 X '[[9,+'\n2 + '[{},'\n2 X '[{},+'\n2 + '[{\",'\n2 + '[{\",+'\n2 + '[{\",+]'\n2 + '[\",+]['\n2 + '[\",+]]'\n2 + '[\",+]{'\n2 + '[\",+]}'\n2 + '[\",+]\"'\n2 + '[\",+],'\n2 + '[\",+].'\n2 + '[\",+]0'\n2 + '[\",+]1'\n2 + '[\",+]2'\n2 + '[\",+]3'\n2 + '[\",+]4'\n2 + '[\",+]5'\n2 + '[\",+]6'\n2 + '[\",+]7'\n2 + '[\",+]8'\n2 + '[\",+]9'\n2 + '[9,['\n2 X '[9,[+'\n2 X '[9,]'\n2 + '[9,{'\n2 X '[9,{+'\n2 X '[9,}'\n2 + '[9,\"'\n2 + '[9,\"+'\n2 + '[9,\"+]'\n2 X '[9,,'\n2 X '[9,.'\n2 + '[9,0'\n2 X '[9,0+'\n2 + '[9,1'\n2 X '[9,1+'\n2 + '[9,2'\n2 X '[9,2+'\n2 + '[9,3'\n2 X '[9,3+'\n2 + '[9,4'\n2 X '[9,4+'\n2 + '[9,5'\n2 X '[9,5+'\n2 + '[9,6'\n2 X '[9,6+'\n2 + '[9,7'\n2 X '[9,7+'\n2 + '[9,8'\n2 X '[9,8+'\n2 + '[9,9'\n2 X '[9,9+'\n2 X '[[[,+'\n2 + '[[[['\n2 X '[[[[*'\n2 + '[[[]'\n2 X '[[[]*'\n2 + '[[[{'\n2 X '[[[{*'\n2 X '[[[}'\n2 + '[[[\"'\n2 + '[[[\"*'\n2 + '[[[\"*,'\n2 + '[[[\"*,+'\n2 + '[[[\"*,+]'\n2 X '[[[.'\n2 + '[[[0'\n2 X '[[[0*'\n2 + '[[[1'\n2 X '[[[1*'\n2 + '[[[2'\n2 X '[[[2*'\n2 + '[[[3'\n2 X '[[[3*'\n2 + '[[[4'\n2 X '[[[4*'\n2 + '[[[5'\n2 X '[[[5*'\n2 + '[[[6'\n2 X '[[[6*'\n2 + '[[[7'\n2 X '[[[7*'\n2 + '[[[8'\n2 X '[[[8*'\n2 + '[[[9'\n2 X '[[[9*'\n2 X '[[]['\n2 * '[[]]'\n2 X '[[]]*'\n2 X '[[]{'\n2 X '[[]}'\n2 X '[[]\"'\n2 X '[[],*'\n2 X '[[].'\n2 X '[[]0'\n2 X '[[]1'\n2 X '[[]2'\n2 X '[[]3'\n2 X '[[]4'\n2 X '[[]5'\n2 X '[[]6'\n2 X '[[]7'\n2 X '[[]8'\n2 X '[[]9'\n2 X '[[{,+'\n2 X '[[{['\n2 X '[[{]'\n2 X '[[{{'\n2 + '[[{}'\n2 X '[[{}*'\n2 + '[[{\"'\n2 + '[[{\"*'\n2 + '[[{\"*,'\n2 + '[[{\"*,+'\n2 + '[[{\"*,+]'\n2 X '[[{.'\n2 X '[[{0'\n2 X '[[{1'\n2 X '[[{2'\n2 X '[[{3'\n2 X '[[{4'\n2 X '[[{5'\n2 X '[[{6'\n2 X '[[{7'\n2 X '[[{8'\n2 X '[[{9'\n2 + '[{\"*,+]['\n2 + '[{\"*,+]]'\n2 + '[{\"*,+]{'\n2 + '[{\"*,+]}'\n2 + '[{\"*,+]\"'\n2 + '[{\"*,+],'\n2 + '[{\"*,+].'\n2 + '[{\"*,+]0'\n2 + '[{\"*,+]1'\n2 + '[{\"*,+]2'\n2 + '[{\"*,+]3'\n2 + '[{\"*,+]4'\n2 + '[{\"*,+]5'\n2 + '[{\"*,+]6'\n2 + '[{\"*,+]7'\n2 + '[{\"*,+]8'\n2 + '[{\"*,+]9'\n2 X '[90,+'\n2 + '[90,'\n2 X '[90['\n2 * '[90]'\n2 X '[90]*'\n2 X '[90{'\n2 X '[90}'\n2 X '[90\"'\n2 X '[90,*'\n2 X '[90.*'\n2 + '[900'\n2 X '[900*'\n2 + '[901'\n2 X '[901*'\n2 + '[902'\n2 X '[902*'\n2 + '[903'\n2 X '[903*'\n2 + '[904'\n2 X '[904*'\n2 + '[905'\n2 X '[905*'\n2 + '[906'\n2 X '[906*'\n2 + '[907'\n2 X '[907*'\n2 + '[908'\n2 X '[908*'\n2 + '[909'\n2 X '[909*'\n2 X '[91,+'\n2 + '[91,'\n2 X '[91['\n2 * '[91]'\n2 X '[91]*'\n2 X '[91{'\n2 X '[91}'\n2 X '[91\"'\n2 X '[91,*'\n2 X '[91.*'\n2 + '[910'\n2 X '[910*'\n2 + '[911'\n2 X '[911*'\n2 + '[912'\n2 X '[912*'\n2 + '[913'\n2 X '[913*'\n2 + '[914'\n2 X '[914*'\n2 + '[915'\n2 X '[915*'\n2 + '[916'\n2 X '[916*'\n2 + '[917'\n2 X '[917*'\n2 + '[918'\n2 X '[918*'\n2 + '[919'\n2 X '[919*'\n2 X '[92,+'\n2 + '[92,'\n2 X '[92['\n2 * '[92]'\n2 X '[92]*'\n2 X '[92{'\n2 X '[92}'\n2 X '[92\"'\n2 X '[92,*'\n2 X '[92.*'\n2 + '[920'\n2 X '[920*'\n2 + '[921'\n2 X '[921*'\n2 + '[922'\n2 X '[922*'\n2 + '[923'\n2 X '[923*'\n2 + '[924'\n2 X '[924*'\n2 + '[925'\n2 X '[925*'\n2 + '[926'\n2 X '[926*'\n2 + '[927'\n2 X '[927*'\n2 + '[928'\n2 X '[928*'\n2 + '[929'\n2 X '[929*'\n2 X '[93,+'\n2 + '[93,'\n2 X '[93['\n2 * '[93]'\n2 X '[93]*'\n2 X '[93{'\n2 X '[93}'\n2 X '[93\"'\n2 X '[93,*'\n2 X '[93.*'\n2 + '[930'\n2 X '[930*'\n2 + '[931'\n2 X '[931*'\n2 + '[932'\n2 X '[932*'\n2 + '[933'\n2 X '[933*'\n2 + '[934'\n2 X '[934*'\n2 + '[935'\n2 X '[935*'\n2 + '[936'\n2 X '[936*'\n2 + '[937'\n2 X '[937*'\n2 + '[938'\n2 X '[938*'\n2 + '[939'\n2 X '[939*'\n2 X '[94,+'\n2 + '[94,'\n2 X '[94['\n2 * '[94]'\n2 X '[94]*'\n2 X '[94{'\n2 X '[94}'\n2 X '[94\"'\n2 X '[94,*'\n2 X '[94.*'\n2 + '[940'\n2 X '[940*'\n2 + '[941'\n2 X '[941*'\n2 + '[942'\n2 X '[942*'\n2 + '[943'\n2 X '[943*'\n2 + '[944'\n2 X '[944*'\n2 + '[945'\n2 X '[945*'\n2 + '[946'\n2 X '[946*'\n2 + '[947'\n2 X '[947*'\n2 + '[948'\n2 X '[948*'\n2 + '[949'\n2 X '[949*'\n2 X '[95,+'\n2 + '[95,'\n2 X '[95['\n2 * '[95]'\n2 X '[95]*'\n2 X '[95{'\n2 X '[95}'\n2 X '[95\"'\n2 X '[95,*'\n2 X '[95.*'\n2 + '[950'\n2 X '[950*'\n2 + '[951'\n2 X '[951*'\n2 + '[952'\n2 X '[952*'\n2 + '[953'\n2 X '[953*'\n2 + '[954'\n2 X '[954*'\n2 + '[955'\n2 X '[955*'\n2 + '[956'\n2 X '[956*'\n2 + '[957'\n2 X '[957*'\n2 + '[958'\n2 X '[958*'\n2 + '[959'\n2 X '[959*'\n2 X '[96,+'\n2 + '[96,'\n2 X '[96['\n2 * '[96]'\n2 X '[96]*'\n2 X '[96{'\n2 X '[96}'\n2 X '[96\"'\n2 X '[96,*'\n2 X '[96.*'\n2 + '[960'\n2 X '[960*'\n2 + '[961'\n2 X '[961*'\n2 + '[962'\n2 X '[962*'\n2 + '[963'\n2 X '[963*'\n2 + '[964'\n2 X '[964*'\n2 + '[965'\n2 X '[965*'\n2 + '[966'\n2 X '[966*'\n2 + '[967'\n2 X '[967*'\n2 + '[968'\n2 X '[968*'\n2 + '[969'\n2 X '[969*'\n2 X '[97,+'\n2 + '[97,'\n2 X '[97['\n2 * '[97]'\n2 X '[97]*'\n2 X '[97{'\n2 X '[97}'\n2 X '[97\"'\n2 X '[97,*'\n2 X '[97.*'\n2 + '[970'\n2 X '[970*'\n2 + '[971'\n2 X '[971*'\n2 + '[972'\n2 X '[972*'\n2 + '[973'\n2 X '[973*'\n2 + '[974'\n2 X '[974*'\n2 + '[975'\n2 X '[975*'\n2 + '[976'\n2 X '[976*'\n2 + '[977'\n2 X '[977*'\n2 + '[978'\n2 X '[978*'\n2 + '[979'\n2 X '[979*'\n2 X '[98,+'\n2 + '[98,'\n2 X '[98['\n2 * '[98]'\n2 X '[98]*'\n2 X '[98{'\n2 X '[98}'\n2 X '[98\"'\n2 X '[98,*'\n2 X '[98.*'\n2 + '[980'\n2 X '[980*'\n2 + '[981'\n2 X '[981*'\n2 + '[982'\n2 X '[982*'\n2 + '[983'\n2 X '[983*'\n2 + '[984'\n2 X '[984*'\n2 + '[985'\n2 X '[985*'\n2 + '[986'\n2 X '[986*'\n2 + '[987'\n2 X '[987*'\n2 + '[988'\n2 X '[988*'\n2 + '[989'\n2 X '[989*'\n2 X '[99,+'\n2 + '[99,'\n2 X '[99['\n2 * '[99]'\n2 X '[99]*'\n2 X '[99{'\n2 X '[99}'\n2 X '[99\"'\n2 X '[99,*'\n2 X '[99.*'\n2 + '[990'\n2 X '[990*'\n2 + '[991'\n2 X '[991*'\n2 + '[992'\n2 X '[992*'\n2 + '[993'\n2 X '[993*'\n2 + '[994'\n2 X '[994*'\n2 + '[995'\n2 X '[995*'\n2 + '[996'\n2 X '[996*'\n2 + '[997'\n2 X '[997*'\n2 + '[998'\n2 X '[998*'\n2 + '[999'\n2 X '[999*'\n2 X '[{}['\n2 * '[{}]'\n2 X '[{}]*'\n2 X '[{}{'\n2 X '[{}}'\n2 X '[{}\"'\n2 X '[{},*'\n2 X '[{}.'\n2 X '[{}0'\n2 X '[{}1'\n2 X '[{}2'\n2 X '[{}3'\n2 X '[{}4'\n2 X '[{}5'\n2 X '[{}6'\n2 X '[{}7'\n2 X '[{}8'\n2 X '[{}9'\n2 + '[\"*,+['\n2 + '[\"*,+[]'\n2 + '[\"*,+{'\n2 + '[\"*,+{]'\n2 + '[\"*,+}'\n2 + '[\"*,+}]'\n2 + '[\"*,+\"'\n2 * '[\"*,+\"]'\n2 + '[\"*,+,'\n2 + '[\"*,+,]'\n2 + '[\"*,+.'\n2 + '[\"*,+.]'\n2 + '[\"*,+0'\n2 + '[\"*,+0]'\n2 + '[\"*,+1'\n2 + '[\"*,+1]'\n2 + '[\"*,+2'\n2 + '[\"*,+2]'\n2 + '[\"*,+3'\n2 + '[\"*,+3]'\n2 + '[\"*,+4'\n2 + '[\"*,+4]'\n2 + '[\"*,+5'\n2 + '[\"*,+5]'\n2 + '[\"*,+6'\n2 + '[\"*,+6]'\n2 + '[\"*,+7'\n2 + '[\"*,+7]'\n2 + '[\"*,+8'\n2 + '[\"*,+8]'\n2 + '[\"*,+9'\n2 + '[\"*,+9]'\nFIXED '[\"*,+\"]'\nNumber of oracle runs required for fixing this input: 965\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}